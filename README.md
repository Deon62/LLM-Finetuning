

# Fine-tuning LLaMA 2 for Medical Question Answering

This project demonstrates fine-tuning a LLaMA 2 model for medical question answering using the Hugging Face Transformers library and the PEFT (Parameter-Efficient Fine-Tuning) library.  The model is trained on a custom dataset of medical terms and their descriptions.

## Requirements

The project requires the following libraries:

*   accelerate
*   peft
*   bitsandbytes
*   transformers
*   trl
*   huggingface_hub
*   datasets
*   torch

These can be installed using pip:



THE MODEL TRAINING WASINTERRUPTED DUE TO NETWORK ISSUES BUT IT IS WORKING AS EXPECTED
